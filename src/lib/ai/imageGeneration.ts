import OpenAI from 'openai'

// Types
export interface ArticleInput {
  title: string
  category: string
  summary: string
}

export interface ImageGenerationResult {
  success: boolean
  imageUrl?: string
  optimizedBuffer?: ArrayBuffer
  error?: string
  fallbackCategory?: string
}

export interface ImageOptimizationResult {
  success: boolean
  optimizedBuffer?: ArrayBuffer
  format?: 'webp' | 'png'
  dimensions?: { width: number; height: number }
  error?: string
}

export interface RateLimitStatus {
  remaining: number
  resetTime: Date
}

// OpenAI client (will be initialized with environment variable)
let openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || 'dummy-key-for-tests',
  dangerouslyAllowBrowser: true // Only for testing - in production this would be server-side
})

// For testing - allow injection of mock client
export function _setOpenAIClient(client: OpenAI) {
  openai = client
}

// Rate limit manager
class RateLimitManager {
  private requests: number = 0
  private resetTime: Date = new Date(Date.now() + 60 * 60 * 1000) // 1 hour from now
  private readonly maxRequests = 5

  canMakeRequest(): boolean {
    if (Date.now() >= this.resetTime.getTime()) {
      this.reset()
    }
    return this.requests < this.maxRequests
  }

  recordRequest(): void {
    if (Date.now() >= this.resetTime.getTime()) {
      this.reset()
    }
    this.requests++
  }

  getStatus(): RateLimitStatus {
    if (Date.now() >= this.resetTime.getTime()) {
      this.reset()
    }
    return {
      remaining: Math.max(0, this.maxRequests - this.requests),
      resetTime: this.resetTime
    }
  }

  reset(): void {
    this.requests = 0
    this.resetTime = new Date(Date.now() + 60 * 60 * 1000)
  }
}

export const rateLimitManager = new RateLimitManager()

// Category-specific prompt themes
const CATEGORY_THEMES: Record<string, string> = {
  Frontend: 'modern web development, code, technology, programming',
  Backend: 'server architecture, databases, APIs, cloud computing',
  Design: 'creative design, UI/UX, visual aesthetics, modern interface',
  Tech: 'technology innovation, digital transformation, modern tech',
  AI: 'artificial intelligence, machine learning, futuristic technology',
  Mobile: 'mobile app development, smartphone interface, mobile technology'
} as const

// Image generation configuration constants
const IMAGE_CONFIG = {
  SIZE: '1792x1024' as const,
  QUALITY: 'standard' as const,
  MODEL: 'dall-e-3' as const,
  TARGET_DIMENSIONS: { width: 768, height: 432 },
  TARGET_FORMAT: 'webp' as const
} as const

// Generate prompt from article data
export function generatePromptFromArticle(article: ArticleInput): string {
  const { title, category, summary } = article
  
  const categoryStyle = CATEGORY_THEMES[category] || 'professional technology'
  
  const basePrompt = `Create a professional blog eyecatch image for an article titled "${title}". Category: ${category}. The image should represent ${categoryStyle} themes. Style: modern, clean, professional, suitable for a tech blog. Resolution should be high quality and suitable for web use.`
  
  return summary ? `${basePrompt} Context: ${summary}` : basePrompt
}

// Main image generation function
export async function generateEyecatchImage(article: ArticleInput): Promise<ImageGenerationResult> {
  try {
    // Check rate limit
    if (!rateLimitManager.canMakeRequest()) {
      return {
        success: false,
        error: 'Rate limit exceeded',
        fallbackCategory: article.category
      }
    }

    // Record the request
    rateLimitManager.recordRequest()

    // Generate prompt
    const prompt = generatePromptFromArticle(article)

    // Call OpenAI DALL-E 3 API
    const response = await openai.images.generate({
      model: IMAGE_CONFIG.MODEL,
      prompt: prompt,
      n: 1,
      size: IMAGE_CONFIG.SIZE,
      quality: IMAGE_CONFIG.QUALITY,
      response_format: 'url'
    })

    // Check if response has data
    if (!response.data || response.data.length === 0) {
      return {
        success: false,
        error: 'No image generated by API',
        fallbackCategory: article.category
      }
    }

    const imageUrl = response.data[0].url
    if (!imageUrl) {
      return {
        success: false,
        error: 'No image URL received from API',
        fallbackCategory: article.category
      }
    }

    // Optimize the generated image
    const optimizationResult = await optimizeImageSize(imageUrl)
    
    return {
      success: true,
      imageUrl: imageUrl,
      optimizedBuffer: optimizationResult.optimizedBuffer
    }

  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Unknown error'
    
    return {
      success: false,
      error: errorMessage,
      fallbackCategory: article.category
    }
  }
}

// Image optimization function
export async function optimizeImageSize(imageUrl: string): Promise<ImageOptimizationResult> {
  try {
    // Fetch the image
    const response = await fetch(imageUrl)
    
    if (!response.ok) {
      return {
        success: false,
        error: `Failed to fetch image: ${response.status}`
      }
    }

    const imageBuffer = await response.arrayBuffer()

    // For now, return the buffer as-is (actual image processing would happen here)
    // In a real implementation, we would use sharp or similar library to:
    // 1. Resize to target dimensions
    // 2. Convert to target format
    // 3. Optimize quality
    return {
      success: true,
      optimizedBuffer: imageBuffer,
      format: IMAGE_CONFIG.TARGET_FORMAT,
      dimensions: IMAGE_CONFIG.TARGET_DIMENSIONS
    }
    
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : 'Unknown error'
    
    return {
      success: false,
      error: `Image optimization failed: ${errorMessage}`
    }
  }
}